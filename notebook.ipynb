{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carpark = 1\n",
    "\n",
    "data = pd.read_csv(\"hf://datasets/oliverbuterbaugh/jersey-carpark-availability/jersey-carpark-availability.csv\")\n",
    "data = data[data['carpark'] == carpark]\n",
    "data.drop(columns='carpark', inplace=True)\n",
    "\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert df columns to tensors\n",
    "spaces = torch.tensor(data['spaces'].values, dtype=torch.float32)\n",
    "prcp = torch.tensor(data['prcp'].values, dtype=torch.float32)\n",
    "wspd = torch.tensor(data['wspd'].values, dtype=torch.float32)\n",
    "wdir = torch.tensor(data['wdir'].values, dtype=torch.float32)\n",
    "hour = torch.tensor(data['hour'].values, dtype=torch.float32)\n",
    "minute = torch.tensor(data['minute'].values, dtype=torch.float32)\n",
    "month = torch.tensor(data['month'].values, dtype=torch.float32)\n",
    "since_holiday = torch.tensor(data['since_holiday'].values, dtype=torch.float32)\n",
    "until_holiday = torch.tensor(data['until_holiday'].values, dtype=torch.float32)\n",
    "weekday = torch.tensor(data['weekday'].values, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode weekday\n",
    "weekday_one_hot = torch.nn.functional.one_hot(weekday, num_classes=7).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert hour and minute to cyclical features\n",
    "hour_sin = torch.sin(hour * 2 * torch.pi / 24)\n",
    "hour_cos = torch.cos(hour * 2 * torch.pi / 24)\n",
    "minute_sin = torch.sin(minute * 2 * torch.pi / 60)\n",
    "minute_cos = torch.cos(minute * 2 * torch.pi / 60)\n",
    "\n",
    "# convert month to cyclical features\n",
    "month_sin = torch.sin((month - 1) * (2 * torch.pi / 12))\n",
    "month_cos = torch.cos((month - 1) * (2 * torch.pi / 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack features into a single tensor\n",
    "features = torch.stack((prcp, wspd, wdir, hour_sin, hour_cos, minute_sin, minute_cos, month_sin, month_cos, since_holiday, until_holiday), dim=1)\n",
    "features = torch.cat((features, weekday_one_hot), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate min and max values\n",
    "min_values = features.min(dim=0, keepdim=True)[0]\n",
    "max_values = features.max(dim=0, keepdim=True)[0]\n",
    "\n",
    "# normalise features\n",
    "normalized_features = (features - min_values) / (max_values - min_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine features and target into a single dataset tensor\n",
    "dataset = torch.cat((normalized_features, spaces.unsqueeze(1)), dim=1)\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set split ratio\n",
    "split_ratio = 0.8\n",
    "split_index = int(split_ratio * len(dataset))\n",
    "\n",
    "# shuffle dataset\n",
    "shuffled_indices = torch.randperm(len(dataset))\n",
    "\n",
    "# split dataset\n",
    "train_indices = shuffled_indices[:split_index]\n",
    "test_indices = shuffled_indices[split_index:]\n",
    "\n",
    "train_dataset = dataset[train_indices]\n",
    "test_dataset = dataset[test_indices]\n",
    "\n",
    "# split features and target\n",
    "train_features = train_dataset[:, :-1]\n",
    "train_targets = train_dataset[:, -1]\n",
    "\n",
    "test_features = test_dataset[:, :-1]\n",
    "test_targets = test_dataset[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features.shape, train_targets.shape, test_features.shape, test_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set device\n",
    "# if torch.cuda.is_available():\n",
    "#     device = torch.device('cuda')\n",
    "# elif torch.backends.mps.is_available():\n",
    "#     device = torch.device(\"mps\")\n",
    "# else:\n",
    "#     device = torch.device('cpu')\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "print('Using device:', device)\n",
    "\n",
    "# move data to device\n",
    "train_features = train_features.to(device)\n",
    "train_targets = train_targets.to(device)\n",
    "test_features = test_features.to(device)\n",
    "test_targets = test_targets.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# initialise model, loss function, optimiser\n",
    "class ParkingSpacePredictor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ParkingSpacePredictor, self).__init__()\n",
    "        self.fc1 = nn.Linear(18, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 32)\n",
    "        self.fc5 = nn.Linear(32, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        return x\n",
    "\n",
    "model = ParkingSpacePredictor().to(device)\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=3e-3)\n",
    "\n",
    "# print parameters\n",
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "# hyperparameters\n",
    "num_epochs = 200\n",
    "batch_size = 128\n",
    "warmup_epochs = num_epochs // 10\n",
    "\n",
    "# learning rate scheduler with warmup and cosine decay\n",
    "def lr_lambda(epoch):\n",
    "    if epoch < warmup_epochs:\n",
    "        return epoch / warmup_epochs\n",
    "    else:\n",
    "        progress = (epoch - warmup_epochs) / (num_epochs - warmup_epochs)\n",
    "        return 0.5 * (1 + math.cos(math.pi * progress))\n",
    "\n",
    "scheduler = LambdaLR(optimizer, lr_lambda=lr_lambda)\n",
    "\n",
    "def create_batches(features, targets, batch_size):\n",
    "    for i in range(0, len(features), batch_size):\n",
    "        yield features[i:i+batch_size], targets[i:i+batch_size]\n",
    "\n",
    "losses = []\n",
    "val_losses = []\n",
    "\n",
    "# training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for batch_features, batch_targets in create_batches(train_features, train_targets, batch_size):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_features)\n",
    "        loss = criterion(outputs.squeeze(), batch_targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    avg_epoch_loss = epoch_loss / len(train_features)\n",
    "    losses.append(avg_epoch_loss)\n",
    "    \n",
    "    # val loss\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_features, batch_targets in create_batches(test_features, test_targets, batch_size):\n",
    "            outputs = model(batch_features)\n",
    "            loss = criterion(outputs.squeeze(), batch_targets)\n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    avg_val_loss = val_loss / len(test_features)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    \n",
    "    # step scheduler\n",
    "    scheduler.step()\n",
    "    \n",
    "    if (epoch) % 20 == 0:\n",
    "        print(f'Epoch {epoch}/{num_epochs}, Loss: {avg_epoch_loss:.4f}, Val Loss: {avg_val_loss:.4f}, LR: {scheduler.get_last_lr()[0]:.6f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot loss\n",
    "plt.plot(losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# eval mode\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "\n",
    "# disable gradient calculation\n",
    "with torch.no_grad():\n",
    "    for batch_features, batch_targets in create_batches(test_features, test_targets, batch_size):\n",
    "        outputs = model(batch_features)\n",
    "        loss = criterion(outputs.squeeze(), batch_targets)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "# average test loss\n",
    "avg_test_loss = test_loss / len(test_features)\n",
    "print(f'Test Loss: {avg_test_loss:.4f}')\n",
    "\n",
    "# MAE\n",
    "def mean_absolute_error(predictions, targets):\n",
    "    return torch.mean(torch.abs(predictions - targets))\n",
    "\n",
    "# RMSE\n",
    "def root_mean_squared_error(predictions, targets):\n",
    "    return torch.sqrt(torch.mean((predictions - targets) ** 2))\n",
    "\n",
    "# R squared\n",
    "def r_squared(predictions, targets):\n",
    "    ss_res = torch.sum((targets - predictions) ** 2)\n",
    "    ss_tot = torch.sum((targets - torch.mean(targets)) ** 2)\n",
    "    return 1 - ss_res / ss_tot\n",
    "\n",
    "# calculate\n",
    "with torch.no_grad():\n",
    "    test_predictions = model(test_features).squeeze()\n",
    "    \n",
    "    mae = mean_absolute_error(test_predictions, test_targets)\n",
    "    rmse = root_mean_squared_error(test_predictions, test_targets)\n",
    "    r2 = r_squared(test_predictions, test_targets)\n",
    "    \n",
    "    print(f'MAE: {mae:.4f}')\n",
    "    print(f'RMSE: {rmse:.4f}')\n",
    "    print(f'R squared: {r2:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aample a subset of the test data\n",
    "num_samples = 10\n",
    "sample_indices = torch.randperm(len(test_features))[:num_samples]\n",
    "sample_features = test_features[sample_indices]\n",
    "sample_targets = test_targets[sample_indices]\n",
    "\n",
    "# get model predictions for the sample\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    sample_predictions = model(sample_features).squeeze()\n",
    "\n",
    "\n",
    "for i in range(num_samples):\n",
    "    print(f\"actual: {int(sample_targets[i].item())}, predicted: {int(sample_predictions[i].item())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "def permutation_importance(model, features, targets, criterion, feature_groups, num_repeats=10):\n",
    "    model.eval()\n",
    "    baseline_loss = criterion(model(features).squeeze(), targets).item()\n",
    "    feature_importances = np.zeros(len(feature_groups))\n",
    "    \n",
    "    for group_idx, group_features in enumerate(feature_groups):\n",
    "        permuted_loss = 0.0\n",
    "        for _ in range(num_repeats):\n",
    "            permuted_features = features.clone()\n",
    "            # Permute all features in the group simultaneously\n",
    "            permuted_indices = torch.randperm(permuted_features.size(0))\n",
    "            for feature_idx in group_features:\n",
    "                permuted_features[:, feature_idx] = permuted_features[:, feature_idx][permuted_indices]\n",
    "            with torch.no_grad():\n",
    "                permuted_loss += criterion(model(permuted_features).squeeze(), targets).item()\n",
    "        permuted_loss /= num_repeats\n",
    "        feature_importances[group_idx] = baseline_loss - permuted_loss\n",
    "    \n",
    "    return feature_importances\n",
    "\n",
    "# Define the groups of features, where each group is a list of indices\n",
    "feature_groups = [\n",
    "    [0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10],\n",
    "    list(range(9, 16))  # This represents the one-hot encoded day_of_week\n",
    "]\n",
    "\n",
    "# Feature names now corresponding to the groups\n",
    "feature_names = ['prcp', 'wspd', 'wdir', 'hour_sin', 'hour_cos', 'minute_sin', 'minute_cos', \n",
    "                 'month_sin', 'month_cos', 'since_holiday', 'until_holiday', 'day_of_week']\n",
    "\n",
    "# Calculate permutation importance\n",
    "feature_importances = permutation_importance(model, test_features, test_targets, criterion, feature_groups)\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(range(len(feature_importances)), feature_importances, align='center')\n",
    "plt.yticks(range(len(feature_importances)), feature_names)\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Feature Importance')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
